# Project Report
### 1.0 Introduction
The purpose of the project is to generate human faces that do not exist in the training set. Four models will be compared: An autoencoder (AE), a variational autoencoder (VAE), a Deep Convolutional Generative Adversarial Network (DC-GAN), and a Variational Autoencoder Generative Adversarial Network (VAE-GAN). All models will be trained on a processed version of the publicly available LFW face dataset.

Our motivation is to learn about different face generation architectures since there are many applications related to face generation, which includes police sketching and data augmentation. We are also interested in assessing the effects of GANs on face generation. We would like to determine if GANs create sharper reconstructions and whether a VAE-GAN has more control over generation due to the restrictions on its latent space [1].

Considering the complexity of the task, machine learning is an appropriate tool for it; face generation is a task that does not lend itself to rules-based systems. Unlike traditional algorithms, machine learning algorithms can learn from large amounts of input data and create new data based on the structure of existing data [2].

### 2.0 Illustration
The four models will be trained on the cleaned data (Figure 1). Quantitative assessment will be conducted by comparing MSE on the training set. However, the DC-GAN does not perform reconstruction so it will be assessed based on the quality of the generated faces. Ease of manipulating embeddings to generate new images will also be considered.

### 3.0 Background & Related Work


### 4.0 Architecture
#### 4.1 VAE
The Variational Autoencoder has 4 convolutional and 4 convolutional transpose layers. Batch normalization [4] is added at all convolutional layers, and the activation function has been changed to leaky ReLU [5] to aid training. The latent space is modeled as a standard Gaussian distribution. The similarity between the learned representation and a standard Gaussian is controlled by penalizing Kullback-Leibler Divergence (KLD) between the two [6]. The weight of the KLD loss relative to the pixel-wise loss is treated as a hyperparameter. New samples can be generated by drawing form a standard Gaussian in the latent space.

#### 4.2 DC-GAN
The DC-GAN consists of a generator (Figure 7) and a discriminator (Figure 8). The generator is made up of five convolutional transpose layers and each layer is followed by a batch normalization and ReLU layer. Since the pixel intensities are normalized to -1 to 1 during data processing, a tanh layer is attached at the end of the generator to remain consistent with the range. Similarly, the discriminator has five convolutional layers and each layer is followed by a leaky ReLU and batch normalization layer. A sigmoid activation will be applied at the end to produce a probability.

#### 4.3 VAE-GAN
The same VAE architecture described above (section 4.1) is used for reconstruction. A 5 layer convolutional, batch-normed, leaky ReLU network with sigmoid output is used as the discriminator. Binary Cross-Entropy loss is used as the objective function for GAN training since the labels are binary values. The training cycle alternates training the discriminator and the generator. During discriminator training, the loss is calculated on equally sized batches of original images, their reconstructions, and standard Gaussian noise reconstructed from the decoder of the VAE. The generator is then trained with the discriminator loss on these same three groups; VAE MSE reconstruction loss and KLD loss are then backpropagated to further incentivize accurate reconstruction and a Gaussian distributed latent space. Currently, the VAE-GAN discriminator either tends to zero or perfect accuracy. Continued tuning in the near future is expected to solve this issue as was done with the DC-GAN.

### 5.0 Quantitative and Qualitative Results 
The performance will be measured quantitatively by comparing the MSE loss on the training data. Generated images will be assessed qualitatively. The lowest MSE is reported below for each model. A DC-GAN has no comparable loss since it has no reconstruction element; a VAE-GAN will also be compared in the future.

#### 5.1 AutoEncoder
The loss of AE drops rapidly at the first few epochs and then settles at an MSE off 0.0077. (Figure 10) Since no constraints are placed on the latent space of the AE, the reconstruction of latent space noise yields nothing of interest. (Figure 11)
		
#### 5.2 VAE
Two VAE models performed well; one with a KLD weighting of 0.1 and the other with a KLD weighting of 0.01. While the model with lower KLD weighting achieved a better MSE loss its generative capabilities were inferior to the other model. This is because the latent space had a looser constraint and its final distribution differed substantially from a standard Gaussian - decoding noise yielded poor results. In both models, KLD loss stays incredibly stable leading us to believe that the distribution is optimized early and later epochs minimize reconstruction loss.

The qualitative examination of reconstructed faces confirms that placing more weight on constraining the latent distribution causes reconstruction quality to suffer. Below are faces generated by reconstructing Gaussian noise from both models’ latent spaces. Rows are ordered by standard deviation; beginning at 0.25 and increasing to 2.0 in 0.25 increments. The first row shows faces considered more prototypical by the VAE; as the standard deviation increases more interesting faces emerge.

#### 5.3 DC-GAN
The DC-GAN generated distorted faces, yet much sharper than what the auto-encoders produced. Without control of the sampling space as in probabilistic models, it is difficult to generate a specific type of face.

#### 5.4 VAE-GAN

### 6.0 Discussion
The AE has limited control over face generation since it is not able to generate faces through random noise in the embedding space. Perturbations of a trained image’s encoding allow modification of a specific image, however, this is not a sufficient amount of generative freedom. 
Our VAE permits controlled generation and achieves lower MSE reconstruction loss. A major drawback of the VAE is the blurriness of its outputs. We believe this model is a large improvement over the regular AE.

The blurred output is solved by an Adversarial network loss function. DC-GAN creates sharper outputs yet has very little control over what image is generated since there are no constraints on the input space; noise is used to generate images in this model. Blurriness and generative control issues are expected to be solved by the VAE-GAN

We will use a Bayesian optimizer to search the hyperparameter space for the VAE. A final KLD weight and VAE architecture will be chosen based on results from default hyperparameters to limit the search space. Lowest combined loss, on a validation set as a sanity check, will be used as the objective of the search. We will not use an optimizer on GAN models since they are very sensitive to hyperparameter choices and their performance is harder to measure with a single objective. Hyperparameter optimization will be done with the HyperOpt library.

### 7.0 Project Difficulty / Quality
