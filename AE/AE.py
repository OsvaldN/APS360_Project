# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YScQ0WYR_I35xMvF1vjRo5RHlADfJY8H
"""

import numpy as np
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
from torch.utils.data.sampler import SubsetRandomSampler
import torchvision.transforms as transforms
import matplotlib.pyplot as plt

#from google.colab import drive
#drive.mount('/content/gdrive')
#!unzip '/content/gdrive/My Drive/face_data.zip'

# split images into train valid and test
#!pip install split-folders
#import split_folders
# Split with a ratio.
#split_folders.ratio('./face_data', output="./output", seed=1337, ratio=(.8, .2)) # default values

def get_AE_data_loader(batch_size=64):
  transform = transforms.ToTensor()

  dataset = torchvision.datasets.ImageFolder(root='./face_data', transform=transform)
  train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=1, shuffle=True)

  return train_loader

train_loader = get_AE_data_loader(batch_size=64)
k = 0
for images, labels in train_loader:
    image = images[0]
    # place the colour channel at the end, instead of at the beginning
    img = np.transpose(image, [1,2,0])
    plt.subplot(3, 5, k+1)
    plt.axis('off')
    plt.imshow(img)  
    k += 1
    if k > 14:
        break

def train(model, num_epochs=5, batch_size=64, learning_rate=1e-4):
    torch.manual_seed(42)
    criterion = nn.MSELoss() # mean square error loss
    optimizer = torch.optim.Adam(model.parameters(),
                                 lr=learning_rate, 
                                 weight_decay=1e-5) # <--
    train_loader = get_AE_data_loader(batch_size=batch_size)
    
    outputs = []
    for epoch in range(num_epochs):
        total_loss = 0.0
        for i, data in enumerate(train_loader):
            img, _ = data
            img = img.cuda()
            recon = model(img)
            loss = criterion(recon, img)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
            total_loss += loss.item()
        total_loss = total_loss / (i+1)
        model_path = "model_{0}_bs{1}_lr{2}_epoch{3}" .format(model.name, batch_size, learning_rate, epoch)
        torch.save(model.state_dict(), model_path)
            
        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(total_loss)))
        outputs.append((epoch, img, recon))
    return outputs

class AE(nn.Module):
    def __init__(self, nc, ndf):
        super(AE, self).__init__()
        self.name = "AE"

        # encoder
        self.encoder = nn.Sequential(
          nn.Conv2d(nc, ndf, kernel_size=4, stride=2, padding=1),
          nn.ReLU(),
          nn.Conv2d(ndf, ndf*2, kernel_size=4, stride=2, padding=1),
          nn.ReLU(),
          nn.Conv2d(ndf*2, ndf*4, kernel_size=4, stride=2, padding=1),
          nn.ReLU(),
          nn.Conv2d(ndf*4, ndf*8, kernel_size=4, stride=2, padding=1)
        )   

        # decoder
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(ndf*8, ndf*4, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(ndf*4, ndf*2, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(ndf*2, ndf, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(ndf, nc, kernel_size=4, stride=2, padding=1),
            nn.Sigmoid()
        )
        
    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# train model 
model = AE(nc=3, ndf=8)
model = model.cuda()
output = train(model, num_epochs=40, batch_size=64, learning_rate=1e-4)

# visualize reconstruction and ori_image at different epochs
imgs = output[39][1].detach().cpu().numpy()
recon = output[39][2].detach().cpu().numpy()
imgs = np.transpose(imgs[0], [1,2,0])
recon = np.transpose(recon[0], [1,2,0])
plt.subplot(1, 2, 1)
plt.imshow(imgs)
plt.subplot(1, 2, 2)
plt.imshow(recon)

# show samples of AE
def show_samples(sample_number = 5):
  train_loader = get_data_loader(sample_number)
  for data, _ in train_loader:
    data = data.cuda()
    recon_emb = model.encoder(data)
    rad = torch.randn(sample_number, 64, 4, 4).cuda()
    mod_emb = recon_emb + rad 
    mod_emb =  model.decoder(mod_emb)
    recon_outputs = model.decoder(recon_emb)
    for i in range(sample_number):
      images = mod_emb
      recon_images = recon_outputs
      ori_images = data 
      image = np.transpose(images[i].detach().cpu().numpy(), [1,2,0])
      recon_image = np.transpose(recon_images[i].detach().cpu().numpy(), [1,2,0])
      ori_image = np.transpose(ori_images[i].detach().cpu().numpy(), [1,2,0])
      plt.subplot(3, sample_number, i+1)
      plt.imshow(image)  
      plt.subplot(3, sample_number, sample_number+i+1)
      plt.imshow(recon_image)
      plt.subplot(3, sample_number, sample_number*2+i+1)
      plt.imshow(ori_image)
    break

show_samples(sample_number = 5)

def generate_rand_sample():
  sample = torch.randn(1, 64, 4, 4)
  sample = sample.cuda()
  recon = model.decoder(sample)
  recon = np.transpose(recon[0].detach().cpu().numpy(), [1,2,0])
  plt.imshow(recon)

generate_rand_sample()